# The Controlled Agency Manifesto

Autonomous AI agents are entering real systems.  
This is not a breakthrough — it is a **risk transition**.

We believe **agency is not inherently beneficial**.  
Agency is power, and power without constraints is liability.

Modern agent systems fail not because they are weak,  
but because they are **insufficiently governed**.

## 1. Autonomy is a design decision, not a default

No system should be autonomous by accident.  
Every increase in agency must be **explicit, justified, and reversible**.

## 2. Instructions are not controls

Telling an agent what it should not do does not create safety.  
Only **technical enforcement** creates real boundaries.

## 3. Autonomy must be graduated

There is no binary state of autonomy.  
There are levels — and each level increases risk.

## 4. The blast radius defines system quality

A constrained agent with limited impact is superior  
to an unconstrained agent with higher intelligence.

## 5. Silence is valid and often optimal

An agent without a clear mandate must remain inactive.  
Proactivity without authorization is failure.

## 6. Cost is a safety constraint

Unbounded computation is a form of loss of control.  
Budgets and limits are safety mechanisms.

## 7. Open systems still require governance

Open source does not remove responsibility.  
It increases the need for clear defaults and boundaries.

---

We do not aim to build agents that can do everything.  
We aim to build agents that **cannot do the wrong thing**.
