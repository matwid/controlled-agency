# Relation to Existing Work

Questions of autonomy, risk, and governance in intelligent systems are not new.

Various taxonomies of autonomy levels, governance frameworks, and safety models
exist in academic literature, industry guidance, and policy discussions.
These efforts often focus on organizational processes, compliance structures,
or high-level categorizations of autonomous behavior.

However, there is currently no widely adopted **normative reference model**
that combines:

- explicitly named autonomy levels for agentic AI systems
- a clear risk-based interpretation of autonomy
- the concept of bounded blast radius as a primary quality metric
- and the assumption of technical enforcement rather than instructional control

The **Controlled Agency** reference does not aim to replace existing frameworks
or research efforts.

Instead, it provides a **practical, operational vocabulary**
for reasoning about agent autonomy in real systems â€”
especially in contexts where agent runtimes are powerful,
open-ended, and increasingly deployed in production environments.

The goal is not to define what agents *can* do,
but to make explicit what they are *allowed* to do,
under which constraints, and at which level of accepted risk.
